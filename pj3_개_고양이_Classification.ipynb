{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNz0J9d2+RZR23ak+kjQp6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenHSKim/tensorflow_study/blob/main/pj3_%EA%B0%9C_%EA%B3%A0%EC%96%91%EC%9D%B4_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dog vs Cat Classification"
      ],
      "metadata": {
        "id": "Bv6TdPQBZm0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전까진 미리 전처리된 데이터를 사용해 딥러닝을 돌려보았습니다.\n",
        "\n",
        "하지만 실전에선 누가 전처리해주지 않고 우리가 직접하는 경우가 많겠죠.\n",
        "\n",
        "쌩 이미지 데이터 백만개를 주었을 때 딥러닝을 어떻게 돌리는지 알아보기위해\n",
        "\n",
        "이번엔 개/고양이 사진을 구분하는 AI를 만들어보도록 합시다.\n",
        "\n",
        "Kaggle 데이터 다운로드 받는 방법부터 시작"
      ],
      "metadata": {
        "id": "G-aMGmvvCW8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Kaggle에서 데이터셋 사용하는 방법\n",
        "1. os로 다운로드 받은 후, !kaggle로 코랩 content에 저장\n",
        "2. !unzip으로 압축 풀기\n",
        "3. 이미지 전처리 작업에서 cat,dog 폴더 직접 만들어주기(/dataset/ 폴더 안에 /cat/과 /dog/ 만들기)"
      ],
      "metadata": {
        "id": "yIaNfO4Vt0O2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CE_f8diz-7x",
        "outputId": "e461377e-5863-4a0e-bcc8-738733ef8e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 793M/812M [00:08<00:00, 173MB/s]\n",
            "100% 812M/812M [00:08<00:00, 104MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 코랩에서 kaggle dataset 다운로드\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩에서 압축 풀기\n",
        "!unzip -q dogs-vs-cats.zip -d ."
      ],
      "metadata": {
        "id": "ueRVDfVT7ugM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "YJgjeoJP8k44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파일 개수 세기\n",
        "import os\n",
        "print(len(os.listdir('/content/train/')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-d7p1FU8zjH",
        "outputId": "7230ef48-1303-4c84-898f-7086a9f50976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번엔 이미지를 숫자로 변환해볼텐데 직접 opencv 라이브러리를 이용해서 손코딩하거나\n",
        "tf keras를 이용해서 쉽게 하거나 둘 중 하나만 하면 됩니다.\n",
        "\n",
        "여기선 후자로 진행합니다.\n",
        "\n",
        "폴더 내의 이미지들을 바로 데이터셋 자료로 만들어주는 고마운 함수가 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "일단 그 함수를 쓰기 위해선 이미지들을 폴더별로 분류하는 작업이 필요합니다.\n",
        "\n",
        "개 사진은 dog 폴더로, 고양이 사진은 cat 폴더로 전부 밀어넣어야하는데 사진이 2만5천장이라\n",
        "\n",
        "손수하려면 드래그하는데도 힘들겠네요. 파이썬 코드로 이미지를 옮겨보도록 합시다.\n",
        "\n",
        "\n",
        "이미지를 각각 폴더에 분류를 잘 했다면\n",
        "\n",
        "이후 전처리를 요약하자면 이게 끝입니다.\n",
        "\n",
        "\n",
        "# 데이터셋 = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#    '사진들어있는폴더경로',\n",
        "#    image_size=(64,64)\n",
        "# )\n",
        "\n",
        "\n",
        "근데 나중에 혼자 공부하며 주의점은 사진 이름이 1.jpg 2.jpg 이렇게 숫자로만 되어있으면 에러가 날 수 있어서\n",
        "\n",
        "숫자로만 되어있으면 앞에 cat1.jpg cat2.jpg 이렇게 이름을 변경해주셔야합니다.\n",
        "\n",
        "os.rename() 을 가져다 쓰시면 파일명 변경해줍니다."
      ],
      "metadata": {
        "id": "e3hYudeMDUSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이미지 전처리"
      ],
      "metadata": {
        "id": "bU0q8EF2rmOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "# tf.keras.preprocessing.image_dataset_from_directory() 이용하기 위한 사전 작업 - cat/dog 폴더 구분\n",
        "# 먼저, content에 dataset 폴더 만들고 cat, dog 폴더 만들기\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i:\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "  if 'dog' in i:\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)"
      ],
      "metadata": {
        "id": "HKWZ47Wy9ckC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras 이용해서 이미지를 숫자화\n",
        "# train_ds에는 ( x(이미지를 행렬로 바꾼 데이터), y(개,고양이 정답 0 또는 1) )가 담김\n",
        "# train_ds를 모델에 집어넣으면 학습 끝\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),\n",
        "    batch_size=32,\n",
        "\n",
        "    # validation data도 준비\n",
        "    subset='training',\n",
        "    validation_split=0.2, # 20% 만큼 validation dataset으로 쪼개기\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "# validation dataset 만들 때 이 형식 따라야 함.\n",
        "# 위 train_ds은 'training'으로 이름짓고, 아래 val_ds는 'validation'으로 이름 짓기\n",
        "# train_ds는 전체 데이터 중 80%, val_ds는 전체 데이터 중 20%\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),\n",
        "    batch_size=32,\n",
        "\n",
        "    subset='validation',\n",
        "    validation_split=0.2,\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "print(train_ds)\n",
        "# print 해보면, 위에서 언급한 대로\n",
        "# ((shape=(None, 64, 64, 3), (shape=(None,)) 모양으로 나오는 것을 알 수 있음.\n",
        "\n",
        "\n",
        "#------------------성능 높히는 코드(보통 사용함)------------------\n",
        "# 이미지 데이터는 현재 텐서 형태로 0~255의 값을 가지고 있음. 이를 0~1로 압축하기\n",
        "def preprocessing_function(i, 정답):\n",
        "  i = tf.cast(i/255.0, tf.float32) # 텐서를 다루기 때문에 i = i/255.0 불가 -> tf.cast() 사용\n",
        "  return i, 정답\n",
        "\n",
        "# map(func): 데이터에 전부 func를 적용해라\n",
        "train_ds = train_ds.map(preprocessing_function)\n",
        "val_ds = val_ds.map(preprocessing_function)\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "# 0~1로 압축한 모습 확인\n",
        "# for i, 정답 in train_ds.take(1): # take(1): 1개만 뽑아서 확인\n",
        "#   print(i)\n",
        "#   print(정답)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiXgxZv6_ofx",
        "outputId": "ce760741-5ed9-4bfc-93f2-2a238091a9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습모델 만들기"
      ],
      "metadata": {
        "id": "9pJh4D4Jrfrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "이전에 했던 것과 유사합니다.\n",
        "이번엔 Dropout Layer를 추가해볼건데 이게 뭐냐면 윗 레이어에 있는 노드들의 일부를 버려주는 레이어입니다.\n",
        "\n",
        "### tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "이렇게 쓰면 윗 레이어의 노드의 20%를 버려줍니다. (0으로 만들어줍니다)\n",
        "\n",
        "이 레이어는 트레이닝용 데이터를 외워버려 validation 데이터보다 매우 정확도가 높아지는 overfitting 현상을 완화하기 위해서 사용합니다."
      ],
      "metadata": {
        "id": "5Cq7itBqDuT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 만들기\n",
        "model = tf.keras.Sequential([\n",
        "    # Convolution 3번 반복 해보기\n",
        "    tf.keras.layers.Conv2D(32, (3,3) ,padding=\"same\", activation='relu', input_shape=(64,64,3)), # RGB 채널: 3\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3) ,padding=\"same\", activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    # dropout: overfitting 방지 위해 노드가 많아보이면 줄임 (여기선 20%)\n",
        "    tf.keras.layers.Dropout(0.2), # 위치는 아무데나. 보통 Conv에선 Pooling 끝나고.\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3) ,padding=\"same\", activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # binary_crossentropy 문제는 sigmoid로 - (분류 문제) 0~1 사이의 확률 제시\n",
        "])\n",
        "\n",
        "# 모델 Summary\n",
        "model.summary()\n",
        "\n",
        "# 모델 컴파일 및 실행\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=(val_ds), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxsO5nctB3SK",
        "outputId": "30d5a6bb-9b44-4c41-bdf7-829420e0917f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1142081 (4.36 MB)\n",
            "Trainable params: 1142081 (4.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 23s 34ms/step - loss: 0.5921 - accuracy: 0.6683 - val_loss: 0.5489 - val_accuracy: 0.7298\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.4759 - accuracy: 0.7714 - val_loss: 0.4155 - val_accuracy: 0.8068\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.4145 - accuracy: 0.8051 - val_loss: 0.4332 - val_accuracy: 0.8034\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.3657 - accuracy: 0.8357 - val_loss: 0.4101 - val_accuracy: 0.8138\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 21s 33ms/step - loss: 0.3216 - accuracy: 0.8599 - val_loss: 0.3551 - val_accuracy: 0.8452\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd670f6cbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}