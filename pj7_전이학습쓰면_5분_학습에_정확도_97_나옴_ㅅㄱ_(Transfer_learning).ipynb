{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkuUju9qf7f4Qj1H+mW1Xy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenHSKim/tensorflow_study/blob/main/pj7_%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5%EC%93%B0%EB%A9%B4_5%EB%B6%84_%ED%95%99%EC%8A%B5%EC%97%90_%EC%A0%95%ED%99%95%EB%8F%84_97_%EB%82%98%EC%98%B4_%E3%85%85%E3%84%B1_(Transfer_learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#전이학습쓰면 5분 학습에 정확도 97% 나옴 ㅅㄱ (Transfer learning)"
      ],
      "metadata": {
        "id": "VeNvcN9gVbSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "오늘은 전이학습이란걸 알아보도록 합시다.\n",
        "\n",
        "Visual Recognition 문제는 수많은 사람들이 이미 도전했던 문제기 때문에  \n",
        "\n",
        "결과가 매우 좋았던 Conv + Pooling 모델들이 이미 존재합니다. 그 모델을 가져와서 개/고양이 분류문제를 풀어보는겁니다.\n",
        "\n",
        "\n",
        "\n",
        "1. 구글 Inception V3모델과 weight파일 로드해서 합치기\n",
        "\n",
        "2. 학습금지 레이어 설정\n",
        "\n",
        "3. Inception 모델에서 중간에 원하는 레이어만 잘라오기\n",
        "\n",
        "4. 내 모델 만들고 (특히 출력층 레이어) Inception과 연결\n",
        "\n",
        "5. 학습 ㄱㄱ\n",
        "\n",
        "이렇게만 하셔도 우리가 풀던 개/고양이 인식 문제에선 epoch 2번에 정확도 95% 이상 달성가능합니다.\n",
        "\n",
        "이런 모델 구글이 쓰라고 공개한건데 안쓸이유가 전혀없겠죠?\n",
        "\n",
        "그래서 이게 요즘 핫한 AI 개발방식이며 많은 대기업 AI 연구원들이 전이학습으로 성과를 날로먹고 있습니다."
      ],
      "metadata": {
        "id": "X_-ygau8Vb40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 개/고양이 분류 프로젝트 가져오기"
      ],
      "metadata": {
        "id": "dAACEuv8YHE6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UF3b-XS7U7jp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYOmpZ3tWz5R",
        "outputId": "fd12ae57-a5f4-494c-af87-1c68fa41704b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 806M/812M [00:10<00:00, 77.7MB/s]\n",
            "100% 812M/812M [00:10<00:00, 82.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats.zip -d ."
      ],
      "metadata": {
        "id": "Yxtvs8fNWzxN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "utv3_jJnXUhD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 만드는 부분까지만 일단 실행"
      ],
      "metadata": {
        "id": "8-BfiI8NYaem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "os.mkdir('/content/dataset/')\n",
        "os.mkdir('/content/dataset/cat')\n",
        "os.mkdir('/content/dataset/dog')\n",
        "\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i:\n",
        "    shutil.copyfile( '/content/train/' + i , '/content/dataset/cat/' + i )\n",
        "  if 'dog' in i:\n",
        "    shutil.copyfile( '/content/train/' + i , '/content/dataset/dog/' + i )\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  '/content/dataset/',\n",
        "  image_size=(150,150),     # 이후에 150x150 사용할 것이기 때문에 이렇게 전처리!\n",
        "  batch_size=64,\n",
        "  subset='training',\n",
        "  validation_split=0.2,\n",
        "  seed=1234\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  '/content/dataset/',\n",
        "  image_size=(150,150),     # 이후에 150x150 사용할 것이기 때문에 이렇게 전처리!\n",
        "  batch_size=64,\n",
        "  subset='validation',\n",
        "  validation_split=0.2,\n",
        "  seed=1234\n",
        ")\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "def 전처리함수(i, 정답):\n",
        "  i = tf.cast( i/255.0, tf.float32 )\n",
        "  return i, 정답\n",
        "\n",
        "train_ds = train_ds.map(전처리함수)\n",
        "val_ds = val_ds.map(전처리함수)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0m8lKZWYUU7",
        "outputId": "04a0d3c4-c9d7-4192-df9e-1e347a35e163"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#전이 학습에는 (1)모델과 (2)학습완료된 weight가 필요함. 다운 받기\n",
        "##1. Inception_v3.h5 파일 다운 받기: 이 파일은 weight 파일임"
      ],
      "metadata": {
        "id": "_D_8MsujYK2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('inception_v3.h5', 'wb').write(r.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm2ALNFKVtQy",
        "outputId": "59740068-94dc-4643-eba7-43be91c3bb6f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87910968"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Inception_v3 모델 가져오기. 이때 주의할 점: **\"항상 불러와서 사용할 땐 input_shape 생각하기!!!\"**"
      ],
      "metadata": {
        "id": "lbHBXGcxZFQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import InceptionV3\n",
        "\n",
        "inception_model = InceptionV3(input_shape=(150,150,3), # 원래는 299x299x3 사용하지만, 나는 변경\n",
        "                              include_top=False,       # top layer: 마지막 출력층 (마지막 Dense 레이어)\n",
        "                              weights=None)            # 위에서 h5 파일 받았기 때문에 여기선 weight 가져오지 않음"
      ],
      "metadata": {
        "id": "rr2ZgET4X1NK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. weight 연결해주기 (weight 파일 + InceptionV3 합치기)"
      ],
      "metadata": {
        "id": "fg1Ue9VGamB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.load_weights('inception_v3.h5')\n",
        "\n",
        "# 모양 확인\n",
        "inception_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHMfdRt9X1LE",
        "outputId": "b95e3b77-3a94-4a8c-f706-336632ddea4d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_188 (Conv2D)         (None, 74, 74, 32)           864       ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_188 (B  (None, 74, 74, 32)           96        ['conv2d_188[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_188 (Activation  (None, 74, 74, 32)           0         ['batch_normalization_188[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_189 (Conv2D)         (None, 72, 72, 32)           9216      ['activation_188[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_189 (B  (None, 72, 72, 32)           96        ['conv2d_189[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_189 (Activation  (None, 72, 72, 32)           0         ['batch_normalization_189[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_190 (Conv2D)         (None, 72, 72, 64)           18432     ['activation_189[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_190 (B  (None, 72, 72, 64)           192       ['conv2d_190[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_190 (Activation  (None, 72, 72, 64)           0         ['batch_normalization_190[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 35, 35, 64)           0         ['activation_190[0][0]']      \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_191 (Conv2D)         (None, 35, 35, 80)           5120      ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_191 (B  (None, 35, 35, 80)           240       ['conv2d_191[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_191 (Activation  (None, 35, 35, 80)           0         ['batch_normalization_191[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_192 (Conv2D)         (None, 33, 33, 192)          138240    ['activation_191[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_192 (B  (None, 33, 33, 192)          576       ['conv2d_192[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_192 (Activation  (None, 33, 33, 192)          0         ['batch_normalization_192[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_192[0][0]']      \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_196 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_196 (B  (None, 16, 16, 64)           192       ['conv2d_196[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_196 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_196[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_194 (Conv2D)         (None, 16, 16, 48)           9216      ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_197 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_196[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_194 (B  (None, 16, 16, 48)           144       ['conv2d_194[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_197 (B  (None, 16, 16, 96)           288       ['conv2d_197[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_194 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_194[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_197 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_197[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_18 (Aver  (None, 16, 16, 192)          0         ['max_pooling2d_9[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_193 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_195 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_194[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_198 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_197[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_199 (Conv2D)         (None, 16, 16, 32)           6144      ['average_pooling2d_18[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_193 (B  (None, 16, 16, 64)           192       ['conv2d_193[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_195 (B  (None, 16, 16, 64)           192       ['conv2d_195[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_198 (B  (None, 16, 16, 96)           288       ['conv2d_198[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_199 (B  (None, 16, 16, 32)           96        ['conv2d_199[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_193 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_193[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_195 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_195[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_198 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_198[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_199 (Activation  (None, 16, 16, 32)           0         ['batch_normalization_199[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_193[0][0]',      \n",
            "                                                                     'activation_195[0][0]',      \n",
            "                                                                     'activation_198[0][0]',      \n",
            "                                                                     'activation_199[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_203 (B  (None, 16, 16, 64)           192       ['conv2d_203[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_203 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_203[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)         (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_203[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_201 (B  (None, 16, 16, 48)           144       ['conv2d_201[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_204 (B  (None, 16, 16, 96)           288       ['conv2d_204[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_201 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_201[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_204 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_204[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_19 (Aver  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_201[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_204[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)         (None, 16, 16, 64)           16384     ['average_pooling2d_19[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_200 (B  (None, 16, 16, 64)           192       ['conv2d_200[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_202 (B  (None, 16, 16, 64)           192       ['conv2d_202[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_205 (B  (None, 16, 16, 96)           288       ['conv2d_205[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_206 (B  (None, 16, 16, 64)           192       ['conv2d_206[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_200 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_200[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_202 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_202[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_205 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_205[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_206 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_206[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_200[0][0]',      \n",
            "                                                                     'activation_202[0][0]',      \n",
            "                                                                     'activation_205[0][0]',      \n",
            "                                                                     'activation_206[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_210 (B  (None, 16, 16, 64)           192       ['conv2d_210[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_210 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_210[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)         (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_210[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_208 (B  (None, 16, 16, 48)           144       ['conv2d_208[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_211 (B  (None, 16, 16, 96)           288       ['conv2d_211[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_208 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_208[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_211 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_211[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_20 (Aver  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_208[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_211[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)         (None, 16, 16, 64)           18432     ['average_pooling2d_20[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_207 (B  (None, 16, 16, 64)           192       ['conv2d_207[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_209 (B  (None, 16, 16, 64)           192       ['conv2d_209[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_212 (B  (None, 16, 16, 96)           288       ['conv2d_212[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_213 (B  (None, 16, 16, 64)           192       ['conv2d_213[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_207 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_207[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_209 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_209[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_212 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_212[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_213 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_213[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_207[0][0]',      \n",
            "                                                                     'activation_209[0][0]',      \n",
            "                                                                     'activation_212[0][0]',      \n",
            "                                                                     'activation_213[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_215 (B  (None, 16, 16, 64)           192       ['conv2d_215[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_215 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_215[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_215[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_216 (B  (None, 16, 16, 96)           288       ['conv2d_216[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_216 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_216[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)         (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_216[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_214 (B  (None, 7, 7, 384)            1152      ['conv2d_214[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_217 (B  (None, 7, 7, 96)             288       ['conv2d_217[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_214 (Activation  (None, 7, 7, 384)            0         ['batch_normalization_214[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_217 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_217[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_214[0][0]',      \n",
            "                                                                     'activation_217[0][0]',      \n",
            "                                                                     'max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_222 (B  (None, 7, 7, 128)            384       ['conv2d_222[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_222 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_222[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_222[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_223 (B  (None, 7, 7, 128)            384       ['conv2d_223[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_223 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_223[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_223[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_219 (B  (None, 7, 7, 128)            384       ['conv2d_219[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_224 (B  (None, 7, 7, 128)            384       ['conv2d_224[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_219 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_219[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_224 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_224[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_219[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_224[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_220 (B  (None, 7, 7, 128)            384       ['conv2d_220[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_225 (B  (None, 7, 7, 128)            384       ['conv2d_225[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_220 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_220[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_225 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_225[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_21 (Aver  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_220[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_225[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_21[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_218 (B  (None, 7, 7, 192)            576       ['conv2d_218[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_221 (B  (None, 7, 7, 192)            576       ['conv2d_221[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_226 (B  (None, 7, 7, 192)            576       ['conv2d_226[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_227 (B  (None, 7, 7, 192)            576       ['conv2d_227[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_218 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_218[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_221 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_221[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_226 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_226[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_227 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_227[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_218[0][0]',      \n",
            "                                                                     'activation_221[0][0]',      \n",
            "                                                                     'activation_226[0][0]',      \n",
            "                                                                     'activation_227[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_232 (B  (None, 7, 7, 160)            480       ['conv2d_232[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_232 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_232[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_232[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_233 (B  (None, 7, 7, 160)            480       ['conv2d_233[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_233 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_233[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_233[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_229 (B  (None, 7, 7, 160)            480       ['conv2d_229[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_234 (B  (None, 7, 7, 160)            480       ['conv2d_234[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_229 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_229[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_234 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_234[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_229[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_234[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_230 (B  (None, 7, 7, 160)            480       ['conv2d_230[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_235 (B  (None, 7, 7, 160)            480       ['conv2d_235[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_230 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_230[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_235 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_235[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_22 (Aver  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_231 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_230[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_235[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_22[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_228 (B  (None, 7, 7, 192)            576       ['conv2d_228[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_231 (B  (None, 7, 7, 192)            576       ['conv2d_231[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_236 (B  (None, 7, 7, 192)            576       ['conv2d_236[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_237 (B  (None, 7, 7, 192)            576       ['conv2d_237[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_228 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_228[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_231 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_231[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_236 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_236[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_237 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_237[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_228[0][0]',      \n",
            "                                                                     'activation_231[0][0]',      \n",
            "                                                                     'activation_236[0][0]',      \n",
            "                                                                     'activation_237[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_242 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_242 (B  (None, 7, 7, 160)            480       ['conv2d_242[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_242 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_242[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_243 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_242[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_243 (B  (None, 7, 7, 160)            480       ['conv2d_243[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_243 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_243[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_244 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_243[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_239 (B  (None, 7, 7, 160)            480       ['conv2d_239[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_244 (B  (None, 7, 7, 160)            480       ['conv2d_244[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_239 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_239[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_244 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_244[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_240 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_239[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_245 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_244[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_240 (B  (None, 7, 7, 160)            480       ['conv2d_240[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_245 (B  (None, 7, 7, 160)            480       ['conv2d_245[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_240 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_240[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_245 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_245[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_23 (Aver  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_241 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_240[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_246 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_245[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_247 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_23[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_238 (B  (None, 7, 7, 192)            576       ['conv2d_238[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_241 (B  (None, 7, 7, 192)            576       ['conv2d_241[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_246 (B  (None, 7, 7, 192)            576       ['conv2d_246[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_247 (B  (None, 7, 7, 192)            576       ['conv2d_247[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_238 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_238[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_241 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_241[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_246 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_246[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_247 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_247[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_238[0][0]',      \n",
            "                                                                     'activation_241[0][0]',      \n",
            "                                                                     'activation_246[0][0]',      \n",
            "                                                                     'activation_247[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_252 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_252 (B  (None, 7, 7, 192)            576       ['conv2d_252[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_252 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_252[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_253 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_252[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_253 (B  (None, 7, 7, 192)            576       ['conv2d_253[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_253 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_253[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_249 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_254 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_253[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_249 (B  (None, 7, 7, 192)            576       ['conv2d_249[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_254 (B  (None, 7, 7, 192)            576       ['conv2d_254[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_249 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_249[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_254 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_254[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_250 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_249[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_255 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_254[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_250 (B  (None, 7, 7, 192)            576       ['conv2d_250[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_255 (B  (None, 7, 7, 192)            576       ['conv2d_255[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_250 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_250[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_255 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_255[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_24 (Aver  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_248 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_251 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_250[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_256 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_255[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_257 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_24[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_248 (B  (None, 7, 7, 192)            576       ['conv2d_248[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_251 (B  (None, 7, 7, 192)            576       ['conv2d_251[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_256 (B  (None, 7, 7, 192)            576       ['conv2d_256[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_257 (B  (None, 7, 7, 192)            576       ['conv2d_257[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_248 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_248[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_251 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_251[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_256 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_256[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_257 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_257[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_248[0][0]',      \n",
            "                                                                     'activation_251[0][0]',      \n",
            "                                                                     'activation_256[0][0]',      \n",
            "                                                                     'activation_257[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_260 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_260 (B  (None, 7, 7, 192)            576       ['conv2d_260[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_260 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_260[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_261 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_260[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_261 (B  (None, 7, 7, 192)            576       ['conv2d_261[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_261 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_261[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_258 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_262 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_261[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_258 (B  (None, 7, 7, 192)            576       ['conv2d_258[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_262 (B  (None, 7, 7, 192)            576       ['conv2d_262[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_258 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_258[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_262 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_262[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_259 (Conv2D)         (None, 3, 3, 320)            552960    ['activation_258[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_263 (Conv2D)         (None, 3, 3, 192)            331776    ['activation_262[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_259 (B  (None, 3, 3, 320)            960       ['conv2d_259[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_263 (B  (None, 3, 3, 192)            576       ['conv2d_263[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_259 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_259[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_263 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_263[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_259[0][0]',      \n",
            "                                                                     'activation_263[0][0]',      \n",
            "                                                                     'max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_268 (Conv2D)         (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_268 (B  (None, 3, 3, 448)            1344      ['conv2d_268[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_268 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_268[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_265 (Conv2D)         (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_269 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_268[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_265 (B  (None, 3, 3, 384)            1152      ['conv2d_265[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_269 (B  (None, 3, 3, 384)            1152      ['conv2d_269[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_265 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_265[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_269 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_269[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_266 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_265[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_267 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_265[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_270 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_269[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_271 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_269[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_25 (Aver  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_264 (Conv2D)         (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_266 (B  (None, 3, 3, 384)            1152      ['conv2d_266[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_267 (B  (None, 3, 3, 384)            1152      ['conv2d_267[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_270 (B  (None, 3, 3, 384)            1152      ['conv2d_270[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_271 (B  (None, 3, 3, 384)            1152      ['conv2d_271[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_272 (Conv2D)         (None, 3, 3, 192)            245760    ['average_pooling2d_25[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_264 (B  (None, 3, 3, 320)            960       ['conv2d_264[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_266 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_266[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_267 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_267[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_270 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_270[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_271 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_271[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_272 (B  (None, 3, 3, 192)            576       ['conv2d_272[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_264 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_264[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_266[0][0]',      \n",
            "                                                                     'activation_267[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 3, 3, 768)            0         ['activation_270[0][0]',      \n",
            " )                                                                   'activation_271[0][0]']      \n",
            "                                                                                                  \n",
            " activation_272 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_272[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_264[0][0]',      \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate_4[0][0]',       \n",
            "                                                                     'activation_272[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_277 (Conv2D)         (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_277 (B  (None, 3, 3, 448)            1344      ['conv2d_277[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_277 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_277[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_274 (Conv2D)         (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_278 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_277[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_274 (B  (None, 3, 3, 384)            1152      ['conv2d_274[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_278 (B  (None, 3, 3, 384)            1152      ['conv2d_278[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_274 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_274[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_278 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_278[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_275 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_274[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_276 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_274[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_279 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_278[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_280 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_278[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_26 (Aver  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_273 (Conv2D)         (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_275 (B  (None, 3, 3, 384)            1152      ['conv2d_275[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_276 (B  (None, 3, 3, 384)            1152      ['conv2d_276[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_279 (B  (None, 3, 3, 384)            1152      ['conv2d_279[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_280 (B  (None, 3, 3, 384)            1152      ['conv2d_280[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_281 (Conv2D)         (None, 3, 3, 192)            393216    ['average_pooling2d_26[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_273 (B  (None, 3, 3, 320)            960       ['conv2d_273[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_275 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_275[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_276 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_276[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_279 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_279[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_280 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_280[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_281 (B  (None, 3, 3, 192)            576       ['conv2d_281[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_273 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_273[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_275[0][0]',      \n",
            "                                                                     'activation_276[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 3, 3, 768)            0         ['activation_279[0][0]',      \n",
            " )                                                                   'activation_280[0][0]']      \n",
            "                                                                                                  \n",
            " activation_281 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_281[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_273[0][0]',      \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_5[0][0]',       \n",
            "                                                                     'activation_281[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21802784 (83.17 MB)\n",
            "Trainable params: 21768352 (83.04 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   원래 layer라면 맨 아래 (Dense) output layer가 있었겠지만, include_top=None 이므로 위엔 없는 상황\n",
        "*   현재 summary에 보이는, 위 레이어들은 Conv+Pooling으로 이미지를 해체/분석해줌\n",
        "*   우리의 상황(개/고양이 분류)에 맞추어 마지막 output layer 작성해야함\n",
        "\n",
        "### 이때 주의할 점!!\n",
        "*   **절대 가져온 레이어는 학습시키면(weight 업데이트 하면) 안됨!**\n",
        "*   **마지막 우리가 만든 output layer만 학습시켜야 함**\n"
      ],
      "metadata": {
        "id": "OzqWHdULa73V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. 학습 금지 레이어 설정하기"
      ],
      "metadata": {
        "id": "FbEatAfEcRqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inception_model.layers은 각 layer을 모두 한 줄씩 보여줌\n",
        "# 일단 모두 trainable 잠가두기\n",
        "for i in inception_model.layers:\n",
        "  i.trainable = False"
      ],
      "metadata": {
        "id": "f-ZW5x1OX1Go"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. 원하는 레이어만 뽑기"
      ],
      "metadata": {
        "id": "D5UQqrctdkOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 summary를 보면, 덩어리가 mixed로 묶여 있는 것을 볼 수 있음\n",
        "# 나는 현재 mixed7 layer 까지만 사용하고 싶을 때,\n",
        "\n",
        "# 마지막 레이어로 mixed7을 가져온다\n",
        "마지막레이어 = inception_model.get_layer('mixed7')\n",
        "\n",
        "print(마지막레이어) # 위로 가서 mixed7을 보면 Concatenate을 해주는 layer임을 알 수 있다.\n",
        "print(마지막레이어.output)\n",
        "print(마지막레이어.output_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9hJ1in1X1ET",
        "outputId": "2f74e586-7952-4e08-c667-c7ba7bd36e1c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.layers.merging.concatenate.Concatenate object at 0x7dcb8751d0f0>\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 768), dtype=tf.float32, name=None), name='mixed7/concat:0', description=\"created by layer 'mixed7'\")\n",
            "(None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. 내 레이어에 연결"
      ],
      "metadata": {
        "id": "76usxXF9eF5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 내 레이어\n",
        "layer1 = tf.keras.layers.Flatten()(마지막레이어.output) # 앞서 결정한 마지막 레이어를 내가 만든 레이어에 연결\n",
        "layer2 = tf.keras.layers.Dense(1024, activation='relu')(layer1)\n",
        "drop1 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer3 = tf.keras.layers.Dense(1, activation='sigmoid')(drop1)\n",
        "\n",
        "# 가져온 Inception model의 레이어 + 내 레이어\n",
        "model = tf.keras.Model(inception_model.input, layer3) # 처음과 끝 (처음: Inception layer의 처음, 끝: 내 레이어의 끝)\n",
        "\n",
        "# !!내 레이어는 학습 해야함 주의!!\n",
        "# 딱 내 레이어에만 해당하는 loss 사용하고, opt는 아무거나\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # loss로 binarycrossentropy!!: 개vs고양이 니깐!\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "2ZEFhBmiX1CO",
        "outputId": "5b275873-0417-4f16-8a10-7e0646a253ab"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-fd261c9ce721>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 )\n\u001b[1;32m   1383\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1679\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1680\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1681\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3271\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4069\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4071\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \"\"\"\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# The default implementation does not use `x`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m         return self.compiled_loss(\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_dtype_and_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtotal_loss_mean_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 )\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0min_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         )\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   2529\u001b[0m     )\n\u001b[1;32m   2530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m     return backend.mean(\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "너무 오래걸려서 일단 취소\n",
        "우리가 쌩으로 했을 땐 acc:85% 정도가 한계였는데, 이건 epoch=2밖에 없는데도 97% 정확도"
      ],
      "metadata": {
        "id": "w51TKXgbjlEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (참고) Finetuning 하는 법"
      ],
      "metadata": {
        "id": "LPE_vLAxiJ2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 일단은 위에서 처럼 모두 False로 막아뒀지만,\n",
        "for i in inception_model.layers:\n",
        "  i.trainable = False\n",
        "\n",
        "# 예를들어 Inception 모델을 mixed6부터 트레이닝을 조금 하고 싶다면:\n",
        "unfreeze = False\n",
        "for i in inception_model.layers:\n",
        "  if i.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "  if unfreeze == True:\n",
        "    i.trainable = True\n",
        "\n",
        "# 위 코드로 원하는 layer을 unfreeze해준 후,\n",
        "# 아래처럼 optimizer를 바꿔주면 된다. optimizer를 learning rate를 아주 약간만 줘서, 미세하게 튜닝(fine tuning)하는 것!\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.00001), metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=2)\n",
        "\n",
        "# (참고) 기존 compile 코드: model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2w7gl33TX09i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}