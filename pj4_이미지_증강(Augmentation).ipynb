{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPikaGOrudu47jwioXoDKHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenHSKim/tensorflow_study/blob/main/pj4_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EC%A6%9D%EA%B0%95(Augmentation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이미지 증강 Image Augmentation"
      ],
      "metadata": {
        "id": "k1cLqAIprSHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 학습을 잘하고 싶으면 이미지의 양을 늘리십시오. 그러면 언제나 더 좋은 결과를 가져옵니다.\n",
        "\n",
        "하지만 이미지 증강 Augmentation 이라는 테크닉도 있습니다.\n",
        "\n",
        "이미지를 살짝살짝씩 돌리고 뒤집고 변형해서 딥러닝을 돌리는겁니다.\n",
        "\n",
        "그럼 모델은 각각 다른 이미지라고 인식하니까요.\n",
        "\n",
        "그럼 조금 더 overfitting이 완화되고, accuracy도 높아집니다.\n",
        "\n",
        "텐서플로우에선 어떻게 해야하는지 알아봅시다.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "텐서플로우의 모든 전처리 레이어는 여기 있습니다.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing"
      ],
      "metadata": {
        "id": "_D6RcFdxszHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Kaggle에서 데이터셋 사용하는 방법\n",
        "1. os로 다운로드 받은 후, !kaggle로 코랩 content에 저장\n",
        "2. !unzip으로 압축 풀기\n",
        "3. 이미지 전처리 작업에서 cat,dog 폴더 직접 만들어주기(/dataset/ 폴더 안에 /cat/과 /dog/ 만들기)"
      ],
      "metadata": {
        "id": "RxOH2GJ6tvjX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaWN8ENDq2-n",
        "outputId": "cdc16be3-8899-4e08-c452-167070459bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            "100% 811M/812M [00:21<00:00, 42.8MB/s]\n",
            "100% 812M/812M [00:21<00:00, 39.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 코랩에서 kaggle dataset 다운로드\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩에서 압축 풀기\n",
        "!unzip -q dogs-vs-cats.zip -d .\n",
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "UCi7OIKqq7j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파일 개수 세기\n",
        "import os\n",
        "print(len(os.listdir('/content/train/')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgOIzMTVq7hw",
        "outputId": "730967da-4ec0-420c-82ab-dcc388756efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이미지 전처리"
      ],
      "metadata": {
        "id": "BK8Ze9jArp_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "# tf.keras.preprocessing.image_dataset_from_directory() 이용하기 위한 사전 작업 - cat/dog 폴더 구분\n",
        "# 먼저, content에 dataset 폴더 만들고 cat, dog 폴더 만들기\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i:\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "  if 'dog' in i:\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)"
      ],
      "metadata": {
        "id": "hfbKtsY-q7fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras 이용해서 이미지를 숫자화\n",
        "# train_ds에는 ( x(이미지를 행렬로 바꾼 데이터), y(개,고양이 정답 0 또는 1) )가 담김\n",
        "# train_ds를 모델에 집어넣으면 학습 끝\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),\n",
        "    batch_size=32,\n",
        "\n",
        "    # validation data도 준비\n",
        "    subset='training',\n",
        "    validation_split=0.2, # 20% 만큼 validation dataset으로 쪼개기\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "# validation dataset 만들 때 이 형식 따라야 함.\n",
        "# 위 train_ds은 'training'으로 이름짓고, 아래 val_ds는 'validation'으로 이름 짓기\n",
        "# train_ds는 전체 데이터 중 80%, val_ds는 전체 데이터 중 20%\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),\n",
        "    batch_size=32,\n",
        "\n",
        "    subset='validation',\n",
        "    validation_split=0.2,\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "print(train_ds)\n",
        "# print 해보면, 위에서 언급한 대로\n",
        "# ((shape=(None, 64, 64, 3), (shape=(None,)) 모양으로 나오는 것을 알 수 있음.\n",
        "\n",
        "\n",
        "#------------------성능 높히는 코드(보통 사용함)------------------\n",
        "# 이미지 데이터는 현재 텐서 형태로 0~255의 값을 가지고 있음. 이를 0~1로 압축하기\n",
        "def preprocessing_function(i, 정답):\n",
        "  i = tf.cast(i/255.0, tf.float32) # 텐서를 다루기 때문에 i = i/255.0 불가 -> tf.cast() 사용\n",
        "  return i, 정답\n",
        "\n",
        "# map(func): 데이터에 전부 func를 적용해라\n",
        "train_ds = train_ds.map(preprocessing_function)\n",
        "val_ds = val_ds.map(preprocessing_function)\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "# 0~1로 압축한 모습 확인\n",
        "# for i, 정답 in train_ds.take(1): # take(1): 1개만 뽑아서 확인\n",
        "#   print(i)\n",
        "#   print(정답)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXFwfXKoq7at",
        "outputId": "c55ab6d2-ba7e-444f-f393-a83b3d5252bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 만들기 & 이미지 증강하기"
      ],
      "metadata": {
        "id": "SgkDUrmzrr9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 방법1: 모델에 이미지 넣기 전에 전처리 layer을 만듦 (최근 나온 쉬운 방식의 이미지 증강)"
      ],
      "metadata": {
        "id": "6UI5k4zkxyRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On-the-fly(Conv모델에 이미지 집어넣기 전에) 이미지에 변형을 줌.\n",
        "예를 들어 epoch=10이라고 하면,\n",
        "\n",
        "*   이미지1.jpg가 들어갈 때마다 같은 이미지로 들어가는 것이 아니라\n",
        "*   epoch의 반복마다 이미지1.jpg의 다른 버전(뒤집기, 돌리기, 확대하기)이 들어감\n",
        "\n"
      ],
      "metadata": {
        "id": "g4Lpn5dkveMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 증강 시 기존과 차이점:\n",
        "* 기존 방식에서는 train_acc는 높지만, val_acc는 상대적으로 낮은 overfitting 문제가 있지만\n",
        "* 이미지 증강 시, train_acc과 val_acc이 비슷해져 overfitting 문제를 해결한다"
      ],
      "metadata": {
        "id": "IQYCWn2kxRyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    #------------------Preprocessing method로 데이터 증강------------------\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal', input_shape=(64,64,3)), # 임의로 뒤집기 # input_shape는 항상 처음에 넣기\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),      # 임의로 돌리기\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),          # 임의로 확대하기\n",
        "    #-------------------------------------------------------------------\n",
        "\n",
        "    # Convolution 3번 반복 해보기\n",
        "    tf.keras.layers.Conv2D(32, (3,3) ,padding=\"same\", activation='relu'), # RGB 채널: 3\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3) ,padding=\"same\", activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    # dropout: overfitting 방지 위해 노드가 많아보이면 줄임 (여기선 20%)\n",
        "    tf.keras.layers.Dropout(0.2), # 위치는 아무데나. 보통 Conv에선 Pooling 끝나고.\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3) ,padding=\"same\", activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # binary_crossentropy 문제는 sigmoid로 - (분류 문제) 0~1 사이의 확률 제시\n",
        "])\n",
        "\n",
        "# 모델 Summary\n",
        "model.summary()\n",
        "\n",
        "# 모델 컴파일 및 실행\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=(val_ds), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrMZANn5q7YX",
        "outputId": "718b86cb-bac1-4814-fc16-d9ce5526c3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_flip (RandomFlip)    (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " random_rotation (RandomRot  (None, 64, 64, 3)         0         \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " random_zoom (RandomZoom)    (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 32, 32, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1142081 (4.36 MB)\n",
            "Trainable params: 1142081 (4.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 34s 43ms/step - loss: 0.6302 - accuracy: 0.6331 - val_loss: 0.6258 - val_accuracy: 0.6776\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 26s 40ms/step - loss: 0.5501 - accuracy: 0.7205 - val_loss: 0.4781 - val_accuracy: 0.7750\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 24s 37ms/step - loss: 0.5050 - accuracy: 0.7520 - val_loss: 0.4838 - val_accuracy: 0.7678\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 27s 42ms/step - loss: 0.4699 - accuracy: 0.7731 - val_loss: 0.4413 - val_accuracy: 0.7926\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 25s 41ms/step - loss: 0.4464 - accuracy: 0.7896 - val_loss: 0.4166 - val_accuracy: 0.8078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b8c2ccdf400>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##방법 2: tensorflow 전통 방식 -> 이미지 전처리(rescaling) 함수를 사용"
      ],
      "metadata": {
        "id": "IcyXNZG9yFCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "생성기 = ImageDataGenerator(\n",
        "    rescale=1./255,         # 스케일링\n",
        "    rotation_range=20,      # 회전\n",
        "    zoom_range=0.15,        # 확대\n",
        "    width_shift_range=0.2,  # 이동\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,       # 굴절\n",
        "    horizontal_flip=True,   # 가로반전\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "metadata": {
        "id": "0mxpCARQyRkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data 전처리\n",
        "# 아래 함수가 결국 \"image_dataset_from_directory()\"와 같은 것\n",
        "트레이닝용 = 생성기.flow_from_directory(\n",
        "    '/content/dataset',\n",
        "    class_mode='binary', # 두 개면 binary, 이상이면 categorical\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    target_size=(64,64)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf5CpN1RzHCi",
        "outputId": "db31287d-1735-46d7-8146-773c178348de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "valdation data 전처리하기에 앞서, val_dataset/cat, val_dataset/dog 폴더 만들기"
      ],
      "metadata": {
        "id": "U3fER_-s0ylo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation data 전처리 -> 절대 빼먹지 말기\n",
        "# 이때, validation용 이미지는 뒤틀 필요가 없음 -> 따라서 뒤틂 작업 제외한 생성기2 선언\n",
        "생성기2 = ImageDataGenerator(rescale=1./255) # 증강 작업 모두 빼고 나누기 255만\n",
        "\n",
        "검증용 = 생성기2.flow_from_directory(\n",
        "    '/content/val_dataset',\n",
        "    class_mode='binary', # 두 개면 binary, 이상이면 categorical\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4iaMNSmz-C3",
        "outputId": "dda5ae74-35e6-45f7-e567-85bcc63164ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit()에 넣으면 됨\n",
        "model.fit(\n",
        "    트레이닝용,\n",
        "    validation_data=검증용,\n",
        "    steps_per_epoch=20000 // 64,\n",
        "    epochs=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEDf8sOxzr8i",
        "outputId": "23647893-ed02-4d7c-acfb-479e0b716485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312/312 [==============================] - 61s 187ms/step - loss: -99401637888.0000 - accuracy: 0.4942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b8b9a159cc0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#참고\n",
        "tf.keras.preprocessing.image.ImageDataGenerator 말고\n",
        "\n",
        "직접 이미지 증강용 레이어를 쓰는 식으로 하는 방법도 있는데\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/data_augmentation#resizing_and_rescaling\n",
        "\n",
        "텐서플로우 추후 버전에서는 이렇게 하라고 권장합니다."
      ],
      "metadata": {
        "id": "7CkpyuYessqB"
      }
    }
  ]
}